{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split Dr-Edited Question Text into its Constituent Parts\n",
    "\n",
    "These are defined as:\n",
    "1. Empathetic Response\n",
    "2. Question\n",
    "3. Extra info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "import nltk\n",
    "import json\n",
    "from IPython.display import display\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "edits_df = pd.read_csv(\"output/edits.csv\")\n",
    "edits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empathy_splitters = \"-,.;:!\"\n",
    "question_splitters = \"?\"\n",
    "\n",
    "def create_question_splits(line):\n",
    "    \"\"\"\n",
    "    Filter out empty items and strip of any trailing whitespace after splitting on sentence splits\n",
    "    \"\"\"\n",
    "    regex_splitter = f\"([{empathy_splitters}{question_splitters}])\"\n",
    "    split = list(filter(None, [x.strip() for x in re.split(regex_splitter, line)]))\n",
    "    split = [x for x in split if len(x) > 1]\n",
    "    return split\n",
    "\n",
    "def split_into_columns(x):\n",
    "    return x[\"empathy\"], x[\"question\"]\n",
    "\n",
    "def select_question(candidates, orig_question):\n",
    "    scores = [fuzz.ratio(c, orig_question) for c in candidates]\n",
    "    return np.argmax(scores)\n",
    "\n",
    "def get_scores(row):\n",
    "    split = create_question_splits(row[\"question_text\"])\n",
    "\n",
    "    return [fuzz.ratio(c, row[\"default_question_text\"]) for c in split]\n",
    "\n",
    "def parse_question_text(row):\n",
    "    text = row[\"question_text\"]\n",
    "    orig_text = row[\"default_question_text\"]\n",
    "\n",
    "    split = create_question_splits(text)\n",
    "\n",
    "    question_start_idx = select_question(split, orig_text)\n",
    "\n",
    "    pred_empathy = \". \".join(split[:question_start_idx])\n",
    "    pred_question = \", \".join(split[question_start_idx:])\n",
    "\n",
    "    return {\n",
    "        \"empathy\": pred_empathy if pred_empathy else None,\n",
    "        \"question\": pred_question,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Empathy Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = edits_df\n",
    "# test_df = edits_df[edits_df[\"question_text\"] == \"Where is your belly pain? Do you have pain in your lower abdomen (lower belly)?\"].head(1)\n",
    "\n",
    "test_df[\"question_parts\"] = test_df.apply(parse_question_text, axis=1)\n",
    "test_df[\"scores\"] = test_df.apply(get_scores, axis=1)\n",
    "test_df[\"empathy\"], test_df[\"question\"] = zip(*test_df[\"question_parts\"].map(split_into_columns))\n",
    "test_df = test_df.drop(\"question_parts\", axis=1)\n",
    "\n",
    "print(\"Proportion empathetic responses:\", test_df[\"empathy\"].count() / len(test_df))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Empathy Response labels to Edits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each empathy response has been manually labelled\n",
    "empathy_labels = pd.read_csv(\"empathy_counts_labelled.csv\")\n",
    "\n",
    "# Map the extracted empathy back to the class it's been labelled as.\n",
    "def apply_label(empathy):\n",
    "    if empathy is None:\n",
    "        return 0\n",
    "    corr_class = empathy_labels[empathy_labels[\"Empathy Utterance\"] == empathy][\"Class\"]\n",
    "    if len(corr_class.values) == 0:\n",
    "        print(\"Can't find label for empathy:\", empathy)\n",
    "        return -1\n",
    "\n",
    "    return corr_class.values[0]\n",
    "\n",
    "test_df[\"empathy_label\"] = test_df[\"empathy\"].map(apply_label).astype(int)\n",
    "test_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8b1ab8091d918d7e972f4bc1e6c56eea6a262f1f4069e9658c413baf02c2dec"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('conv_ht': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
